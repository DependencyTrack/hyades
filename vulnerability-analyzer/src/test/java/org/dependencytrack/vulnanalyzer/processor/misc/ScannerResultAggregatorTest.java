/*
 * This file is part of Dependency-Track.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 * SPDX-License-Identifier: Apache-2.0
 * Copyright (c) OWASP Foundation. All Rights Reserved.
 */
package org.dependencytrack.vulnanalyzer.processor.misc;

import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.TestInputTopic;
import org.apache.kafka.streams.TestOutputTopic;
import org.apache.kafka.streams.TopologyTestDriver;
import org.apache.kafka.streams.kstream.Consumed;
import org.apache.kafka.streams.kstream.Produced;
import org.apache.kafka.streams.state.KeyValueStore;
import org.dependencytrack.proto.KafkaProtobufSerde;
import org.dependencytrack.proto.vulnanalysis.internal.v1beta1.ScannerResultAggregate;
import org.dependencytrack.proto.vulnanalysis.v1.ScanKey;
import org.dependencytrack.proto.vulnanalysis.v1.ScannerResult;
import org.junit.jupiter.api.AfterEach;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;

import java.time.Duration;
import java.time.Instant;
import java.util.UUID;

import static org.assertj.core.api.Assertions.assertThat;
import static org.dependencytrack.proto.vulnanalysis.v1.ScanStatus.SCAN_STATUS_FAILED;
import static org.dependencytrack.proto.vulnanalysis.v1.ScanStatus.SCAN_STATUS_PENDING;
import static org.dependencytrack.proto.vulnanalysis.v1.ScanStatus.SCAN_STATUS_SUCCESSFUL;
import static org.dependencytrack.proto.vulnanalysis.v1.Scanner.SCANNER_INTERNAL;
import static org.dependencytrack.proto.vulnanalysis.v1.Scanner.SCANNER_OSSINDEX;
import static org.dependencytrack.proto.vulnanalysis.v1.Scanner.SCANNER_SNYK;
import static org.dependencytrack.proto.vulnanalysis.v1.Scanner.SCANNER_TRIVY;

class ScannerResultAggregatorTest {

    private TopologyTestDriver testDriver;
    private TestInputTopic<ScanKey, ScannerResultAggregate> inputTopic;
    private TestOutputTopic<ScanKey, ScannerResultAggregate> outputTopic;
    private KeyValueStore<ScanKey, ScannerResultAggregate> stateStore;

    @BeforeEach
    void beforeEach() {
        final var processorSupplier = new ScannerResultAggregatorSupplier("aggregator-store", Duration.ofSeconds(5), Duration.ofSeconds(30));

        final var keySerde = new KafkaProtobufSerde<>(ScanKey.parser());
        final var valueSerde = new KafkaProtobufSerde<>(ScannerResultAggregate.parser());

        final var streamsBuilder = new StreamsBuilder();
        streamsBuilder
                .stream("input-topic", Consumed.with(keySerde, valueSerde))
                .processValues(processorSupplier)
                .to("output-topic", Produced.with(keySerde, valueSerde));

        testDriver = new TopologyTestDriver(streamsBuilder.build());
        inputTopic = testDriver.createInputTopic("input-topic", keySerde.serializer(), valueSerde.serializer());
        outputTopic = testDriver.createOutputTopic("output-topic", keySerde.deserializer(), valueSerde.deserializer());
        stateStore = testDriver.getKeyValueStore("aggregator-store");
    }

    @AfterEach
    void afterEach() {
        if (testDriver != null) {
            testDriver.close();
        }
    }

    @Test
    void testWithSingleResult() {
        final var scanKey = ScanKey.newBuilder()
                .setComponentUuid(UUID.randomUUID().toString())
                .setScanToken(UUID.randomUUID().toString())
                .build();

        final var aggregate = ScannerResultAggregate.newBuilder()
                .putResults(SCANNER_OSSINDEX.name(), ScannerResult.newBuilder()
                        .setScanner(SCANNER_OSSINDEX)
                        .setStatus(SCAN_STATUS_SUCCESSFUL)
                        .build())
                .build();

        inputTopic.pipeInput(scanKey, aggregate);

        // The aggregate is complete (contains no results with status PENDING),
        // and must be forwarded.
        assertThat(outputTopic.readRecordsToList()).satisfiesExactly(
                record -> {
                    assertThat(record.key()).isEqualTo(scanKey);
                    assertThat(record.value().getResultsCount()).isEqualTo(1);
                    assertThat(record.value().getResultsOrThrow(SCANNER_OSSINDEX.name()).getStatus()).isEqualTo(SCAN_STATUS_SUCCESSFUL);
                    assertThat(record.value().getLastUpdated().getSeconds()).isNotZero();
                }
        );

        // The aggregate is complete (contains no results with status PENDING),
        // thus there's no need to hold on to it.
        assertThat(stateStore.get(scanKey)).isNull();
    }

    @Test
    void testWithMultipleResults() {
        final var scanKey = ScanKey.newBuilder()
                .setComponentUuid(UUID.randomUUID().toString())
                .setScanToken(UUID.randomUUID().toString())
                .build();

        inputTopic.pipeInput(scanKey, ScannerResultAggregate.newBuilder()
                .putResults(SCANNER_OSSINDEX.name(), ScannerResult.newBuilder()
                        .setScanner(SCANNER_OSSINDEX)
                        .setStatus(SCAN_STATUS_SUCCESSFUL)
                        .build())
                .putResults(SCANNER_SNYK.name(), ScannerResult.newBuilder()
                        .setScanner(SCANNER_SNYK)
                        .setStatus(SCAN_STATUS_PENDING)
                        .build())
                .putResults(SCANNER_TRIVY.name(), ScannerResult.newBuilder()
                        .setScanner(SCANNER_TRIVY)
                        .setStatus(SCAN_STATUS_PENDING)
                        .build())
                .build());

        // The aggregate is incomplete (contains results with status PENDING),
        // thus no record must be forwarded, and a record in the state store must exist.
        assertThat(outputTopic.readRecordsToList()).isEmpty();
        assertThat(stateStore.get(scanKey)).isNotNull();

        inputTopic.pipeInput(scanKey, ScannerResultAggregate.newBuilder()
                .putResults(SCANNER_OSSINDEX.name(), ScannerResult.newBuilder()
                        .setScanner(SCANNER_OSSINDEX)
                        .setStatus(SCAN_STATUS_PENDING)
                        .build())
                .putResults(SCANNER_SNYK.name(), ScannerResult.newBuilder()
                        .setScanner(SCANNER_SNYK)
                        .setStatus(SCAN_STATUS_FAILED)
                        .build())
                .putResults(SCANNER_TRIVY.name(), ScannerResult.newBuilder()
                        .setScanner(SCANNER_TRIVY)
                        .setStatus(SCAN_STATUS_FAILED)
                        .build())
                .build());

        // The aggregate is complete now (contains no results with status PENDING),
        // and must be forwarded.
        assertThat(outputTopic.readRecordsToList()).satisfiesExactly(
                record -> {
                    assertThat(record.key()).isEqualTo(scanKey);
                    assertThat(record.value().getResultsCount()).isEqualTo(3);
                    assertThat(record.value().getResultsOrThrow(SCANNER_OSSINDEX.name()).getStatus()).isEqualTo(SCAN_STATUS_SUCCESSFUL);
                    assertThat(record.value().getResultsOrThrow(SCANNER_SNYK.name()).getStatus()).isEqualTo(SCAN_STATUS_FAILED);
                    assertThat(record.value().getResultsOrThrow(SCANNER_TRIVY.name()).getStatus()).isEqualTo(SCAN_STATUS_FAILED);
                    assertThat(record.value().getLastUpdated().getSeconds()).isNotZero();
                }
        );

        // The aggregate is complete (contains no results with status PENDING),
        // thus there's no need to hold on to it anymore.
        assertThat(stateStore.get(scanKey)).isNull();
    }

    @Test
    void testExpiration() {
        final var scanKey = ScanKey.newBuilder()
                .setComponentUuid(UUID.randomUUID().toString())
                .setScanToken(UUID.randomUUID().toString())
                .build();

        inputTopic.pipeInput(scanKey, ScannerResultAggregate.newBuilder()
                .putResults(SCANNER_OSSINDEX.name(), ScannerResult.newBuilder()
                        .setScanner(SCANNER_OSSINDEX)
                        .setStatus(SCAN_STATUS_SUCCESSFUL)
                        .build())
                .putResults(SCANNER_SNYK.name(), ScannerResult.newBuilder()
                        .setScanner(SCANNER_SNYK)
                        .setStatus(SCAN_STATUS_PENDING)
                        .build())
                .putResults(SCANNER_TRIVY.name(), ScannerResult.newBuilder()
                        .setScanner(SCANNER_TRIVY)
                        .setStatus(SCAN_STATUS_PENDING)
                        .build())
                .build());

        // The aggregate is incomplete (contains results with status PENDING),
        // thus no record must be forwarded, and a record in the state store must exist.
        assertThat(outputTopic.readRecordsToList()).isEmpty();
        assertThat(stateStore.get(scanKey)).isNotNull();

        // Publish a complete aggregate for a different scanKey, and for a different scanner,
        // but 45 seconds (stream time) AFTER the previous one.
        inputTopic.pipeInput(
                ScanKey.newBuilder()
                        .setComponentUuid(UUID.randomUUID().toString())
                        .setScanToken(UUID.randomUUID().toString())
                        .build(),
                ScannerResultAggregate.newBuilder()
                        .putResults(SCANNER_INTERNAL.name(), ScannerResult.newBuilder()
                                .setScanner(SCANNER_INTERNAL)
                                .setStatus(SCAN_STATUS_SUCCESSFUL)
                                .build())
                        .build(),
                Instant.now().plusSeconds(45));

        assertThat(outputTopic.readRecordsToList()).satisfiesExactly(
                record -> {
                    assertThat(record.key()).isNotEqualTo(scanKey);
                    assertThat(record.value().getResultsCount()).isEqualTo(1);
                    assertThat(record.value().getResultsOrThrow(SCANNER_INTERNAL.name()).getStatus()).isEqualTo(SCAN_STATUS_SUCCESSFUL);
                    assertThat(record.value().getLastUpdated().getSeconds()).isNotZero();
                }
        );

        // The first partial aggregate has expired (maxLifeTime is 30 seconds),
        // and its store entry was removed. The second record was complete and
        // never persisted to the store in the first place.
        // Thus, the store must be empty at this point.
        assertThat(stateStore.approximateNumEntries()).isZero();
    }

}