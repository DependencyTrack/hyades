package org.acme;

import io.quarkus.kafka.client.serialization.ObjectMapperSerde;
import org.acme.common.KafkaTopic;
import org.acme.config.InternalScannerConfig;
import org.acme.config.OssIndexConfig;
import org.acme.config.SnykConfig;
import org.acme.model.AnalyzerIdentity;
import org.acme.model.Component;
import org.acme.model.VulnerabilityResult;
import org.acme.processor.internal.InternalScannerProcessorSupplier;
import org.acme.processor.ossindex.OssIndexProcessorSupplier;
import org.acme.processor.snyk.SnykProcessorSupplier;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.common.utils.Bytes;
import org.apache.kafka.streams.KeyValue;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.Topology;
import org.apache.kafka.streams.kstream.Branched;
import org.apache.kafka.streams.kstream.Consumed;
import org.apache.kafka.streams.kstream.Grouped;
import org.apache.kafka.streams.kstream.Joined;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.KTable;
import org.apache.kafka.streams.kstream.Materialized;
import org.apache.kafka.streams.kstream.Named;
import org.apache.kafka.streams.kstream.Produced;
import org.apache.kafka.streams.state.KeyValueStore;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import javax.enterprise.context.ApplicationScoped;
import javax.enterprise.inject.Produces;
import javax.inject.Inject;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.Map;
import java.util.UUID;

import static org.acme.commonutil.KafkaStreamsUtil.processorNameConsume;
import static org.acme.commonutil.KafkaStreamsUtil.processorNameProduce;

@ApplicationScoped
public class VulnerabilityAnalyzerTopology {

    private static final Logger LOGGER = LoggerFactory.getLogger(VulnerabilityAnalyzerTopology.class);

    private final InternalScannerConfig internalScannerConfig;
    private final OssIndexConfig ossIndexConfig;
    private final SnykConfig snykConfig;
    private final InternalScannerProcessorSupplier internalScannerProcessorSupplier;
    private final OssIndexProcessorSupplier ossIndexProcessorSupplier;
    private final SnykProcessorSupplier snykProcessorSupplier;

    @Inject
    public VulnerabilityAnalyzerTopology(final InternalScannerConfig internalScannerConfig,
                                         final OssIndexConfig ossIndexConfig,
                                         final SnykConfig snykConfig,
                                         final InternalScannerProcessorSupplier internalScannerProcessorSupplier,
                                         final OssIndexProcessorSupplier ossIndexProcessorSupplier,
                                         final SnykProcessorSupplier snykProcessorSupplier) {
        this.internalScannerConfig = internalScannerConfig;
        this.ossIndexConfig = ossIndexConfig;
        this.snykConfig = snykConfig;
        this.internalScannerProcessorSupplier = internalScannerProcessorSupplier;
        this.ossIndexProcessorSupplier = ossIndexProcessorSupplier;
        this.snykProcessorSupplier = snykProcessorSupplier;
    }

    record AnalysisProgress(Component component, Map<AnalyzerIdentity, Boolean> completed) {
    }

    record AnalyzerComponent(AnalyzerIdentity identity, Component component) {
    }

    @Produces
    public Topology topology() {
        final var streamsBuilder = new StreamsBuilder();

        final var componentSerde = new ObjectMapperSerde<>(Component.class);
        final var vulnResultSerde = new ObjectMapperSerde<>(VulnerabilityResult.class);
        final var progressSerde = new ObjectMapperSerde<>(AnalysisProgress.class);

        final KStream<UUID, Component> componentStream = streamsBuilder
                .stream(KafkaTopic.VULN_ANALYSIS_COMPONENT.getName(), Consumed
                        .with(Serdes.UUID(), componentSerde)
                        .withName(processorNameConsume(KafkaTopic.VULN_ANALYSIS_COMPONENT)));

        final KStream<String, VulnerabilityResult> vulnerabilityStream = streamsBuilder
                .stream(KafkaTopic.VULN_ANALYSIS_VULNERABILITY.getName(), Consumed
                        .with(Serdes.String(), vulnResultSerde)
                        .withName(processorNameConsume(KafkaTopic.VULN_ANALYSIS_VULNERABILITY)));

        final KStream<UUID, VulnerabilityResult> resultStream = streamsBuilder
                .stream(KafkaTopic.VULN_ANALYSIS_RESULT.getName(), Consumed
                        .with(Serdes.UUID(), vulnResultSerde)
                        .withName(processorNameConsume(KafkaTopic.VULN_ANALYSIS_RESULT)));

        // For every incoming component, determine which scanners are enabled, and capable
        // of scanning it. Enrich the component with "completed" flags for each applicable
        // scanner, and store that in a KTable.
        final KTable<UUID, AnalysisProgress> expectedScannerResultsTable = componentStream
                .mapValues(component -> {
                    final var completed = new HashMap<AnalyzerIdentity, Boolean>();
                    if (shouldScanWithInternalScanner(component)) {
                        completed.put(AnalyzerIdentity.INTERNAL_ANALYZER, false);
                    }
                    if (shouldScanWithOssIndex(component)) {
                        completed.put(AnalyzerIdentity.OSSINDEX_ANALYZER, false);
                    }
                    if (shouldScanWithSnyk(component)) {
                        completed.put(AnalyzerIdentity.SNYK_ANALYZER, false);
                    }
                    // TODO: Handle cases where no scanner is applicable
                    return new AnalysisProgress(component, completed);
                }, Named.as("determine_expected_scanner_results"))
                .toTable(Named.as("materialize_to_expected-scanner-results_table"), Materialized
                        .<UUID, AnalysisProgress, KeyValueStore<Bytes, byte[]>>as("expected-scanner-results-table")
                        .withKeySerde(Serdes.UUID())
                        .withValueSerde(progressSerde)
                        .withStoreType(Materialized.StoreType.IN_MEMORY));

        // For every incoming component, determine which scanners are enabled, and capable
        // of scanning it. Then, submit components to the topics of all applicable scanners.
        // Records are re-keyed from UUIDs to identifiers (CPE, PURL), where PURL always takes
        // precedence over CPE.
        // The assumption is that PURL will cover most cases, and having one or the other outlier
        // where PURL and CPE refer to different components is acceptable in practice.
        componentStream
                .flatMap((uuid, component) -> {
                    final var components = new ArrayList<KeyValue<String, AnalyzerComponent>>();
                    if (shouldScanWithInternalScanner(component)) {
                        components.add(KeyValue.pair(component.getUuid().toString(), new AnalyzerComponent(AnalyzerIdentity.INTERNAL_ANALYZER, component)));
                    }
                    if (shouldScanWithOssIndex(component)) {
                        components.add(KeyValue.pair(component.getPurl().getCoordinates(), new AnalyzerComponent(AnalyzerIdentity.OSSINDEX_ANALYZER, component)));
                    }
                    if (shouldScanWithSnyk(component)) {
                        components.add(KeyValue.pair(component.getPurl().getCoordinates(), new AnalyzerComponent(AnalyzerIdentity.SNYK_ANALYZER, component)));
                    }
                    return components;
                }, Named.as("determine_applicable_scanners"))
                .split(Named.as("applicable_scanner"))
                .branch(this::isForInternalScanner, Branched
                        .<String, AnalyzerComponent>withConsumer(stream -> stream
                                .mapValues(AnalyzerComponent::component)
                                .to(KafkaTopic.VULN_ANALYSIS_SCANNER_INTERNAL.getName(), Produced
                                        .with(Serdes.String(), componentSerde)
                                        .withName(processorNameProduce(KafkaTopic.VULN_ANALYSIS_SCANNER_INTERNAL))))
                        .withName("-internal"))
                .branch(this::isForOssIndex, Branched
                        .<String, AnalyzerComponent>withConsumer(stream -> stream
                                .mapValues(AnalyzerComponent::component)
                                .to(KafkaTopic.VULN_ANALYSIS_SCANNER_OSSINDEX.getName(), Produced
                                        .with(Serdes.String(), componentSerde)
                                        .withName(processorNameProduce(KafkaTopic.VULN_ANALYSIS_SCANNER_OSSINDEX))))
                        .withName("-ossindex"))
                .branch(this::isForSnyk, Branched
                        .<String, AnalyzerComponent>withConsumer(stream -> stream
                                .mapValues(AnalyzerComponent::component)
                                .to(KafkaTopic.VULN_ANALYSIS_SCANNER_SNYK.getName(), Produced
                                        .with(Serdes.String(), componentSerde)
                                        .withName(processorNameProduce(KafkaTopic.VULN_ANALYSIS_SCANNER_SNYK))))
                        .withName("-snyk"))
                .noDefaultBranch();

        resultStream
                // Filter out completion events, otherwise we'll be running into an infinite loop.
                .filter((uuid, result) -> AnalyzerIdentity.NONE != result.getIdentity(),
                        Named.as("filter_out_completion_events"))
                .join(expectedScannerResultsTable, (result, progress) -> {
                    final Map<AnalyzerIdentity, Boolean> completed = new HashMap<>(progress.completed());
                    completed.put(result.getIdentity(), true);
                    return new AnalysisProgress(progress.component(), completed);
                }, Joined
                        .with(Serdes.UUID(), vulnResultSerde, progressSerde)
                        .withName("join_results_with_expected_scanner_results"))
                .groupByKey(Grouped.as("group_by_component_uuid"))
                .aggregate(
                        () -> new AnalysisProgress(null, null),
                        (key, value, aggregate) -> {
                            final Map<AnalyzerIdentity, Boolean> completed;
                            if (aggregate.completed() != null) {
                                completed = aggregate.completed();
                                value.completed().entrySet().stream()
                                        .filter(Map.Entry::getValue)
                                        .map(Map.Entry::getKey)
                                        .forEach(identity -> completed.put(identity, true));
                            } else {
                                completed = value.completed();
                            }
                            return new AnalysisProgress(value.component(), completed);
                        }, Named.as("aggregate_analysis_progress"),
                        Materialized
                                .<UUID, AnalysisProgress, KeyValueStore<Bytes, byte[]>>as("analysis-progress-aggregate-table")
                                .withKeySerde(Serdes.UUID())
                                .withValueSerde(progressSerde)
                                .withStoreType(Materialized.StoreType.IN_MEMORY))
                .toStream(Named.as("stream_completed_scans"))
                // We receive an event for every change of the aggregate here,
                // so suppress events that do not represent a completed scan.
                .filter((uuid, progress) -> progress.completed().values().stream().allMatch(Boolean.TRUE::equals),
                        Named.as("filter_completed_scans"))
                .mapValues((uuid, progress) -> {
                    final var result = new VulnerabilityResult();
                    result.setIdentity(AnalyzerIdentity.NONE);
                    result.setFailureReason("completed"); // TODO: Use dedicated field or status
                    return result;
                }, Named.as("map_to_completion_event"))
                .to(KafkaTopic.VULN_ANALYSIS_RESULT.getName(), Produced
                        .with(Serdes.UUID(), vulnResultSerde)
                        .withName(processorNameProduce(KafkaTopic.VULN_ANALYSIS_RESULT, "completion_event")));

        if (internalScannerConfig.enabled()) {
            streamsBuilder
                    .stream(KafkaTopic.VULN_ANALYSIS_SCANNER_INTERNAL.getName(), Consumed
                            .with(Serdes.String(), componentSerde)
                            .withName(processorNameConsume(KafkaTopic.VULN_ANALYSIS_SCANNER_INTERNAL)))
                    .process(internalScannerProcessorSupplier, Named.as("scan_with_internal-scanner"))
                    .to(KafkaTopic.VULN_ANALYSIS_VULNERABILITY.getName(), Produced
                            .with(Serdes.String(), vulnResultSerde)
                            .withName(processorNameProduce(KafkaTopic.VULN_ANALYSIS_VULNERABILITY, "internal-scanner_results")));
        }
        if (ossIndexConfig.enabled()) {
            streamsBuilder
                    .stream(KafkaTopic.VULN_ANALYSIS_SCANNER_OSSINDEX.getName(), Consumed
                            .with(Serdes.String(), componentSerde)
                            .withName(processorNameConsume(KafkaTopic.VULN_ANALYSIS_SCANNER_OSSINDEX)))
                    .process(ossIndexProcessorSupplier, Named.as("scan_with_ossindex"))
                    .to(KafkaTopic.VULN_ANALYSIS_VULNERABILITY.getName(), Produced
                            .with(Serdes.String(), vulnResultSerde)
                            .withName(processorNameProduce(KafkaTopic.VULN_ANALYSIS_VULNERABILITY, "ossindex_results")));
        }
        if (snykConfig.enabled()) {
            streamsBuilder
                    .stream(KafkaTopic.VULN_ANALYSIS_SCANNER_SNYK.getName(), Consumed
                            .with(Serdes.String(), componentSerde)
                            .withName(processorNameConsume(KafkaTopic.VULN_ANALYSIS_SCANNER_SNYK)))
                    .process(snykProcessorSupplier, Named.as("scan_with_snyk"))
                    .to(KafkaTopic.VULN_ANALYSIS_VULNERABILITY.getName(), Produced
                            .with(Serdes.String(), vulnResultSerde)
                            .withName(processorNameProduce(KafkaTopic.VULN_ANALYSIS_VULNERABILITY, "snyk_results")));
        }

        vulnerabilityStream
                .selectKey((identifier, result) -> result.getComponent().getUuid(),
                        Named.as("re-key_vuln_result_from_identifier_to_component_uuid"))
                .to(KafkaTopic.VULN_ANALYSIS_RESULT.getName(), Produced
                        .with(Serdes.UUID(), vulnResultSerde)
                        .withName(processorNameProduce(KafkaTopic.VULN_ANALYSIS_RESULT)));

        return streamsBuilder.build();
    }

    private boolean shouldScanWithInternalScanner(final Component component) {
        return internalScannerConfig.enabled()
                && (component.getCpe() != null || component.getPurl() != null);
    }

    private boolean shouldScanWithOssIndex(final Component component) {
        return ossIndexConfig.enabled() && component.getPurl() != null;
    }

    private boolean shouldScanWithSnyk(final Component component) {
        return snykConfig.enabled() && component.getPurl() != null;
    }

    private boolean isForInternalScanner(final String identifier, final AnalyzerComponent component) {
        return AnalyzerIdentity.INTERNAL_ANALYZER == component.identity();
    }

    private boolean isForOssIndex(final String identifier, final AnalyzerComponent component) {
        return AnalyzerIdentity.OSSINDEX_ANALYZER == component.identity();
    }

    private boolean isForSnyk(final String identifier, final AnalyzerComponent component) {
        return AnalyzerIdentity.SNYK_ANALYZER == component.identity();
    }

}
