/*
 * This file is part of Dependency-Track.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 * SPDX-License-Identifier: Apache-2.0
 * Copyright (c) OWASP Foundation. All Rights Reserved.
 */
package org.dependencytrack.vulnanalyzer.processor.scanner.trivy;

import io.github.resilience4j.circuitbreaker.CircuitBreaker;
import io.github.resilience4j.core.IntervalFunction;
import io.micrometer.core.instrument.MeterRegistry;
import io.quarkus.cache.Cache;
import jakarta.ws.rs.core.MultivaluedHashMap;
import jakarta.ws.rs.core.MultivaluedMap;
import org.apache.commons.codec.digest.DigestUtils;
import org.cyclonedx.proto.v1_4.Bom;
import org.dependencytrack.proto.vulnanalysis.internal.v1beta1.ScanTask;
import org.dependencytrack.proto.vulnanalysis.v1.ScanKey;
import org.dependencytrack.proto.vulnanalysis.v1.ScanStatus;
import org.dependencytrack.proto.vulnanalysis.v1.Scanner;
import org.dependencytrack.proto.vulnanalysis.v1.ScannerResult;
import org.dependencytrack.vulnanalyzer.client.trivy.Application;
import org.dependencytrack.vulnanalyzer.client.trivy.BlobInfo;
import org.dependencytrack.vulnanalyzer.client.trivy.OS;
import org.dependencytrack.vulnanalyzer.client.trivy.Package;
import org.dependencytrack.vulnanalyzer.client.trivy.PackageInfo;
import org.dependencytrack.vulnanalyzer.client.trivy.PurlType;
import org.dependencytrack.vulnanalyzer.client.trivy.PutRequest;
import org.dependencytrack.vulnanalyzer.client.trivy.Report;
import org.dependencytrack.vulnanalyzer.client.trivy.Result;
import org.dependencytrack.vulnanalyzer.client.trivy.TrivyClient;
import org.dependencytrack.vulnanalyzer.client.trivy.TrivyResponse;
import org.dependencytrack.vulnanalyzer.client.trivy.Vulnerability;
import org.dependencytrack.vulnanalyzer.config.TrivyConfig;
import org.dependencytrack.vulnanalyzer.processor.retry.RetryStatus;
import org.dependencytrack.vulnanalyzer.processor.retry.RetryableRecord;
import org.dependencytrack.vulnanalyzer.processor.retry.RetryingBatchProcessor;
import org.dependencytrack.vulnanalyzer.util.ProcessorUtils;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.NoSuchElementException;
import java.util.Optional;

import static org.dependencytrack.vulnanalyzer.util.PurlUtils.parsePurl;

public class TrivyProcessor extends RetryingBatchProcessor<String, ScanTask, ScanKey, ScannerResult, ScanKey> {

    private static final Logger LOGGER = LoggerFactory.getLogger(TrivyProcessor.class);

    private final TrivyClient client;
    private final TrivyConfig config;
    private final Cache cache;
    private final CircuitBreaker circuitBreaker;
    private static final String VULNERABLE = "vulnerable";
    private static final String NOT_VULNERABLE = "not_vulnerable";

    TrivyProcessor(final TrivyClient trivyClient, final TrivyConfig config, final Cache cache, final CircuitBreaker circuitBreaker,
                   final String batchStoreName, final String retryStoreName, final IntervalFunction retryIntervalFunction,
                   final int retryMaxAttempts, final MeterRegistry meterRegistry) {
        super(retryStoreName, retryIntervalFunction, retryMaxAttempts, meterRegistry, batchStoreName, config.batchInterval(), config.batchSize());
        this.client = trivyClient;
        this.config = config;
        this.cache = cache;
        this.circuitBreaker = circuitBreaker;
    }

    @Override
    public void process(final RetryableRecord<String, ScanTask> record) {
        addToBatch(record);
    }

    @Override
    protected ScanKey retryKey(final String key, final ScanTask value) {
        return value.getKey();
    }

    @Override
    protected void onRetry(final RetryableRecord<String, ScanTask> record) {
        addToBatch(record);
    }

    @Override
    protected void onMaxRetriesExceeded(final RetryableRecord<String, ScanTask> record) {
        reportFailure(record, new RuntimeException("Max retry attempts exceeded"));
    }

    @Override
    public void addToBatch(final RetryableRecord<String, ScanTask> record) {
        final Optional<Report> cachedReport = getCachedReport(record.key());
        if (cachedReport.isPresent()) {
            LOGGER.debug("Processing cached report for {}", record);
            processReport(cachedReport.get(), List.of(record));
            return;
        }

        if (batchStore.get(record.value().getKey()) == null) {
            batchStore.put(record.value().getKey(), record);
        } else {
            LOGGER.warn("Record {} is already in the current batch; Dropping", record);
            return;
        }

        // Note: approximateNumEntries may over-report or under-report when RocksDB is used.
        // It is possible that this condition will be true, even though the store contains
        // more or less entries than config.batchSize.
        // This is an acceptable trade-off here, because it's still a better option than reading
        // entries from the store too often (as it involves de-serializing all of them).
        if (batchStore.approximateNumEntries() >= config.batchSize()) {
            final List<RetryableRecord<String, ScanTask>> batch = currentBatch();
            analyzeBatch(batch);
        }
    }

    @Override
    public void analyzeBatch(final List<RetryableRecord<String, ScanTask>> batch) {
        LOGGER.info("Analyzing batch of {} records", batch.size());
        super.analyzeBatch(batch);

        final MultivaluedMap<String, RetryableRecord<String, ScanTask>> purlRecords = new MultivaluedHashMap<>();
        for (final RetryableRecord<String, ScanTask> record : batch) {
            purlRecords.add(record.key(), record);
        }

        analyzeBlobInfo(batch, purlRecords);
    }

    private void analyzeBlobInfo(List<RetryableRecord<String, ScanTask>> batch, MultivaluedMap<String, RetryableRecord<String, ScanTask>> purlRecords) {

        var pkgs = new HashMap<String, PackageInfo>();
        var apps = new HashMap<String, Application>();
        var os = new HashMap<String, OS>();

        for (final var record : batch) {
            var purlParsed = parsePurl(record.key());

            if (purlParsed.isPresent()) {
                var purl = purlParsed.get();
                var appType = PurlType.getApp(purl.getType());
                var name = purl.getName();
                if (!PurlType.UNKNOWN.getAppType().equals(appType)) {
                    if (!PurlType.Constants.PACKAGES.equals(appType)) {
                        if (apps.get(appType) == null) {
                            apps.put(appType, new Application(appType, new ArrayList<>(), new ArrayList<>()));
                        }
                        var app = apps.get(appType);
                        app.packages().add(new Package(name, purl.getVersion(), null, null));

                    } else {

                        var pkgType = purl.getType().toString();
                        String arch = null;
                        Integer epoch = null;

                        if (purl.getQualifiers() != null) {
                            arch = purl.getQualifiers().get("arch");

                            String tmpEpoch = purl.getQualifiers().get("epoch");
                            if (tmpEpoch != null) {
                                epoch = Integer.parseInt(tmpEpoch);
                            }

                            String distro = purl.getQualifiers().get("distro");

                            if (distro != null) {
                                pkgType = distro;
                            }
                        }

                        if (pkgs.get(pkgType) == null) {
                            pkgs.put(pkgType, new PackageInfo(null));
                        }

                        var pkg = pkgs.get(pkgType);

                        pkg.packages().add(new Package<>(purl.getName(), purl.getVersion(),  arch != null ? arch : "x86_64", epoch));
                    }
                }
            }
        }

        final var infos = new ArrayList<>();

        if (!apps.isEmpty()) {
            infos.add(new BlobInfo<>(null, null, List.of(apps.values().toArray(new Application[]{})), null));
        }

        pkgs.forEach((key, value) -> {
            var info = new BlobInfo<>(null,
                    os.get(key) != null ? os.get(key) : null,
                    List.of(apps.values().toArray(new Application[]{})),
                    List.of(new PackageInfo[]{value}));
            infos.add(info);
        });

        final ArrayList<Result> results;
        try {
            results = circuitBreaker.executeSupplier(() -> analyzeBlob(infos.toArray(new BlobInfo[]{})));
            batch.forEach(record -> reportRetryStatus(record, RetryStatus.SUCCEEDED));
        } catch (Throwable e) {
            if (ProcessorUtils.isRetryable(e)) {
                batch.forEach(record -> {
                    LOGGER.warn("Encountered retryable exception while analyzing {}: {}", record, e.getMessage());
                    scheduleForRetry(record);
                });
            } else {
                batch.forEach(record -> {
                    LOGGER.error("Encountered non-retryable exception while analyzing {}", record, e);
                    reportFailure(record, e);
                });
            }
            return;
        }
        handleResults(purlRecords, results);
    }

    private void handleResults(final MultivaluedMap<String, RetryableRecord<String, ScanTask>> purlRecords, final ArrayList<Result> results) {
        for (Result result : results) {
            for (Vulnerability vulnerability : result.vulnerabilities()) {
                var key = vulnerability.pkgIdentifier().purl();
                if (!config.ignoreUnfixedEnabled() || vulnerability.status() == 3) {
                    final List<RetryableRecord<String, ScanTask>> affectedRecords = purlRecords.get(key);
                    if (affectedRecords == null) {
                        LOGGER.warn("Reported coordinates do not match any records: " + key);
                        continue;
                    } else {
                        purlRecords.remove(key);
                    }
                    Report mappedReport = getMappedReport(result, key);
                    processReport(mappedReport, affectedRecords);
                    cacheReport(mappedReport);
                }
            }
        }
        for (final Map.Entry<String, List<RetryableRecord<String, ScanTask>>> unmatchedRecords : purlRecords.entrySet()) {
            // If no results have been identified for a given PURL.
            // Whenever we have PURLs left that we couldn't correlate with a Trivy result,
            // we have to assume it's not vulnerable.
            LOGGER.debug("No results were returned for purl {}", unmatchedRecords.getKey());
            for (final RetryableRecord<String, ScanTask> record : unmatchedRecords.getValue()) {
                final ScannerResult result = ScannerResult.newBuilder()
                        .setScanner(Scanner.SCANNER_TRIVY)
                        .setStatus(ScanStatus.SCAN_STATUS_SUCCESSFUL)
                        .build();
                context().forward(record.withKey(record.value().getKey()).withValue(result).withTimestamp(context().currentSystemTimeMs()));
                reportScanResult(NOT_VULNERABLE);
                cacheReport(new Report(unmatchedRecords.getKey(), Bom.newBuilder().build()));
            }
        }
    }

    private Report getMappedReport(Result result, String purl) {
        Bom bom = org.dependencytrack.vulnanalyzer.client.trivy.ModelConverterToCdx.convert(result.vulnerabilities());
        return new Report(purl, bom);
    }

    private ArrayList<Result> analyzeBlob(final BlobInfo[] blobs) {
        ArrayList<Result> output = new ArrayList<>();

        for (final BlobInfo info : blobs) {

            String hash = DigestUtils.sha256Hex(java.util.UUID.randomUUID().toString());
            final var blob = new PutRequest("sha256:" + hash, info);

            client.putBlob(blob);
            TrivyResponse response = client.scanBlob(blob);
            if (response != null && response.results() != null) {
                LOGGER.debug("received response from trivy");
                output.addAll(response.results());
            }
            client.deleteBlob(List.of(blob.diffID()));

        }
        return output;
    }

    private Optional<Report> getCachedReport(final String purl) {
        try {
            final Report cachedReport = cache.<String, Report>get(purl.toLowerCase(),
                    key -> {
                        throw new NoSuchElementException();
                    }).await().indefinitely();
            return Optional.of(cachedReport);
        } catch (Exception e) {
            return Optional.empty();
        }
    }

    private void cacheReport(final Report report) {
        cache.get(report.purl().toLowerCase(), key -> report).await().indefinitely();
    }

    private void processReport(final Report report, List<RetryableRecord<String, ScanTask>> affectedRecords) {
        for (final RetryableRecord<String, ScanTask> record : affectedRecords) {
            final var result = ScannerResult.newBuilder()
                    .setScanner(Scanner.SCANNER_TRIVY)
                    .setStatus(ScanStatus.SCAN_STATUS_SUCCESSFUL)
                    .setBom(report.bom())
                    .build();
            context().forward(record.withKey(record.value().getKey()).withValue(result).withTimestamp(context().currentSystemTimeMs()));
            reportScanResult(report.bom().getVulnerabilitiesList().isEmpty() ? NOT_VULNERABLE : VULNERABLE);
        }
    }

    private void reportFailure(final RetryableRecord<String, ScanTask> record, final Throwable failureCause) {
        final var result = ScannerResult.newBuilder()
                .setScanner(Scanner.SCANNER_TRIVY)
                .setStatus(ScanStatus.SCAN_STATUS_FAILED)
                .setFailureReason(failureCause.getMessage())
                .build();
        context().forward(record.withKey(record.value().getKey()).withValue(result).withTimestamp(context().currentSystemTimeMs()));
        reportRetryStatus(record, RetryStatus.FAILED);
        reportScanResult("failed");
    }
}
