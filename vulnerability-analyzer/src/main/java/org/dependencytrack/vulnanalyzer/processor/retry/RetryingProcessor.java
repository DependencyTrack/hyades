package org.dependencytrack.vulnanalyzer.processor.retry;

import io.github.resilience4j.core.IntervalFunction;
import io.micrometer.core.instrument.Counter;
import io.micrometer.core.instrument.Gauge;
import io.micrometer.core.instrument.Meter;
import io.micrometer.core.instrument.MeterRegistry;
import io.micrometer.core.instrument.Tag;
import org.apache.kafka.streams.KeyValue;
import org.apache.kafka.streams.processor.Cancellable;
import org.apache.kafka.streams.processor.PunctuationType;
import org.apache.kafka.streams.processor.api.ContextualProcessor;
import org.apache.kafka.streams.processor.api.ProcessorContext;
import org.apache.kafka.streams.processor.api.Record;
import org.apache.kafka.streams.state.KeyValueIterator;
import org.apache.kafka.streams.state.KeyValueStore;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.time.Duration;
import java.util.Optional;
import java.util.Set;

/**
 * A {@link ContextualProcessor} capable of handling retries in a stateful, yet non-blocking way.
 *
 * @param <KI> Key type for incoming records
 * @param <VI> Value type for incoming records
 * @param <KO> Key type for outgoing records
 * @param <VO> Value type for outgoing records
 * @param <KR> Key type for retries
 */
public abstract class RetryingProcessor<KI, VI, KO, VO, KR> extends ContextualProcessor<KI, VI, KO, VO> {

    private final String storeName;
    private final IntervalFunction intervalFunction;
    private final int maxAttempts;
    private final MeterRegistry meterRegistry;
    private final Logger logger;

    private KeyValueStore<KR, RetryableRecord<KI, VI>> store;
    private Cancellable punctuator;
    private Counter recordsConsumedCounter;
    private Gauge storeEntriesGauge;

    /**
     * @param storeName        Name of the {@link KeyValueStore} used for retries
     * @param intervalFunction The {@link IntervalFunction} used to calculate the delay before the next retry attempt
     * @param maxAttempts      Maximum amount of retry attempts to allow
     * @param meterRegistry    The {@link MeterRegistry} to register metrics in
     */
    protected RetryingProcessor(final String storeName, final IntervalFunction intervalFunction,
                                final int maxAttempts, final MeterRegistry meterRegistry) {
        this.storeName = storeName;
        this.intervalFunction = intervalFunction;
        this.maxAttempts = maxAttempts;
        this.meterRegistry = meterRegistry;
        this.logger = LoggerFactory.getLogger(getClass());
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public void init(final ProcessorContext<KO, VO> context) {
        super.init(context);

        store = context().getStateStore(storeName);
        punctuator = context().schedule(Duration.ofSeconds(1), PunctuationType.WALL_CLOCK_TIME, this::punctuateRetry);

        recordsConsumedCounter = Counter.builder("kafka.stream.processor.records.consumed")
                .tags(Set.of(
                        Tag.of("thread_id", Thread.currentThread().getName()),
                        Tag.of("task_id", context().taskId().toString()),
                        Tag.of("processor", getClass().getSimpleName())
                ))
                .register(meterRegistry);
        storeEntriesGauge = Gauge.builder("kafka.stream.store.entries", store::approximateNumEntries)
                .description("Total number of entries in the retry state store")
                .tags(Set.of(
                        Tag.of("thread_id", Thread.currentThread().getName()),
                        Tag.of("task_id", context().taskId().toString()),
                        Tag.of("processor", getClass().getSimpleName()),
                        Tag.of("store", storeName)
                ))
                .register(meterRegistry);
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public void process(final Record<KI, VI> record) {
        recordsConsumedCounter.increment();

        final RetryableRecord<KI, VI> retryableRecord = store.get(retryKey(record.key(), record.value()));
        if (retryableRecord == null) {
            process(RetryableRecord.fromRecord(record));
        } else {
            logger.warn("Component {} is already scheduled for retry at {}; Dropping", record.value(), retryableRecord.nextRetryAt());
        }
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public void close() {
        Optional.ofNullable(storeEntriesGauge).ifPresent(Meter::close);
        Optional.ofNullable(punctuator).ifPresent(Cancellable::cancel);
    }

    protected abstract void process(final RetryableRecord<KI, VI> record);

    /**
     * Extract the key to be used for storing the {@link RetryableRecord} in the retry {@link KeyValueStore}.
     *
     * @param key   Key of the {@link RetryableRecord} to extract the retry key for
     * @param value Value of the {@link RetryableRecord} to extract the retry key for
     * @return The retry key
     */
    protected abstract KR retryKey(final KI key, final VI value);

    /**
     * Callback for records that are due for retry.
     *
     * @param record The {@link RetryableRecord} to retry
     */
    protected abstract void onRetry(final RetryableRecord<KI, VI> record);

    /**
     * Callback for records that exceeded the maximum amount of retry attempts.
     *
     * @param record The failed {@link RetryableRecord}
     */
    protected abstract void onMaxRetriesExceeded(final RetryableRecord<KI, VI> record);

    /**
     * Schedule a record for retry.
     *
     * @param record The {@link RetryableRecord} to retry
     */
    protected void scheduleForRetry(final RetryableRecord<KI, VI> record) {
        if (record.retryAttempts() < maxAttempts) {
            store.put(retryKey(record.key(), record.value()),
                    record.withNextRetryAt(calculateNextRetryTimestamp(record)));
        } else {
            logger.warn("Max retry attempts ({}) exceeded for record {}", maxAttempts, record);
            onMaxRetriesExceeded(record);
        }
    }

    /**
     * Report the final {@link RetryStatus} of a given {@link RetryableRecord}.
     *
     * @param record The {@link RetryableRecord} to report the status for
     * @param status The {@link RetryStatus} to report
     */
    protected void reportRetryStatus(final RetryableRecord<?, ?> record, final RetryStatus status) {
        final String statusText = switch (status) {
            case SUCCEEDED -> record.retryAttempts() == 0 ? "succeeded_without_retry" : "succeeded_with_retry";
            case FAILED -> record.retryAttempts() == 0 ? "failed_without_retry" : "failed_with_retry";
        };

        Counter.builder("kafka.stream.processor.retries")
                .tags(Set.of(
                        Tag.of("thread_id", Thread.currentThread().getName()),
                        Tag.of("task_id", context().taskId().toString()),
                        Tag.of("processor", getClass().getSimpleName()),
                        Tag.of("status", statusText),
                        Tag.of("attempts", Integer.toString(record.retryAttempts()))
                ))
                .register(meterRegistry)
                .increment();
    }

    private void punctuateRetry(final long timestamp) {
        try (final KeyValueIterator<KR, RetryableRecord<KI, VI>> valueIterator = store.all()) {
            while (valueIterator.hasNext()) {
                final KeyValue<KR, RetryableRecord<KI, VI>> keyValue = valueIterator.next();
                if (keyValue != null) {
                    final RetryableRecord<KI, VI> record = keyValue.value;
                    if (record.nextRetryAt() <= timestamp) {
                        logger.debug("Retrying record {}", keyValue.value);
                        store.delete(keyValue.key);
                        onRetry(keyValue.value);
                    }
                }
            }
        }
    }

    private long calculateNextRetryTimestamp(final RetryableRecord<?, ?> record) {
        final long delay = intervalFunction.apply(record.retryAttempts() + 1);
        return context().currentSystemTimeMs() + delay;
    }

}
