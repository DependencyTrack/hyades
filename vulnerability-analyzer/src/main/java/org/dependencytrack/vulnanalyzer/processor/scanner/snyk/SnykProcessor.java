/*
 * This file is part of Dependency-Track.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 * SPDX-License-Identifier: Apache-2.0
 * Copyright (c) OWASP Foundation. All Rights Reserved.
 */
package org.dependencytrack.vulnanalyzer.processor.scanner.snyk;

import io.github.resilience4j.circuitbreaker.CircuitBreaker;
import io.github.resilience4j.core.IntervalFunction;
import io.micrometer.core.instrument.MeterRegistry;
import io.quarkus.cache.Cache;
import jakarta.ws.rs.core.MultivaluedMap;
import org.cyclonedx.proto.v1_4.Bom;
import org.dependencytrack.common.cwe.CweResolver;
import org.dependencytrack.proto.vulnanalysis.internal.v1beta1.ScanTask;
import org.dependencytrack.proto.vulnanalysis.v1.ScanKey;
import org.dependencytrack.proto.vulnanalysis.v1.ScanStatus;
import org.dependencytrack.proto.vulnanalysis.v1.Scanner;
import org.dependencytrack.proto.vulnanalysis.v1.ScannerResult;
import org.dependencytrack.vulnanalyzer.client.snyk.Issue;
import org.dependencytrack.vulnanalyzer.client.snyk.MetaError;
import org.dependencytrack.vulnanalyzer.client.snyk.ModelConverterToCdx;
import org.dependencytrack.vulnanalyzer.client.snyk.Page;
import org.dependencytrack.vulnanalyzer.client.snyk.PageData;
import org.dependencytrack.vulnanalyzer.client.snyk.PageMeta;
import org.dependencytrack.vulnanalyzer.client.snyk.Report;
import org.dependencytrack.vulnanalyzer.client.snyk.ReportRequest;
import org.dependencytrack.vulnanalyzer.client.snyk.SeveritySource;
import org.dependencytrack.vulnanalyzer.client.snyk.SnykClient;
import org.dependencytrack.vulnanalyzer.config.SnykConfig;
import org.dependencytrack.vulnanalyzer.processor.retry.RetryStatus;
import org.dependencytrack.vulnanalyzer.processor.retry.RetryableRecord;
import org.dependencytrack.vulnanalyzer.processor.retry.RetryingBatchProcessor;
import org.dependencytrack.vulnanalyzer.util.ProcessorUtils;
import org.jboss.resteasy.reactive.common.util.MultivaluedTreeMap;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Collection;
import java.util.List;
import java.util.Map;
import java.util.NoSuchElementException;
import java.util.Optional;
import java.util.Set;
import java.util.TreeSet;

public class SnykProcessor extends RetryingBatchProcessor<String, ScanTask, ScanKey, ScannerResult, ScanKey> {

    private static final Logger LOGGER = LoggerFactory.getLogger(SnykProcessor.class);

    private final SnykClient client;
    private final SnykConfig config;
    private final Cache cache;
    private final CircuitBreaker circuitBreaker;
    private final List<SeveritySource> severitySourcePriority;

    private static final String VULNERABLE = "vulnerable";
    private static final String NOT_VULNERABLE = "not_vulnerable";

    SnykProcessor(final SnykClient snykClient, final SnykConfig config, final Cache cache, final CircuitBreaker circuitBreaker,
                  final List<SeveritySource> severitySourcePriority, final String batchStoreName,
                  final String retryStoreName, final IntervalFunction retryIntervalFunction,
                  final int retryMaxAttempts, final MeterRegistry meterRegistry) {
        super(retryStoreName, retryIntervalFunction, retryMaxAttempts, meterRegistry, batchStoreName, config.batchInterval(), config.batchSize());
        this.client = snykClient;
        this.config = config;
        this.cache = cache;
        this.circuitBreaker = circuitBreaker;
        this.severitySourcePriority = severitySourcePriority;
    }

    @Override
    public void process(final RetryableRecord<String, ScanTask> record) {
        addToBatch(record);
    }

    @Override
    protected ScanKey retryKey(final String key, final ScanTask value) {
        return value.getKey();
    }

    @Override
    protected void onRetry(final RetryableRecord<String, ScanTask> record) {
        addToBatch(record);
    }

    @Override
    protected void onMaxRetriesExceeded(final RetryableRecord<String, ScanTask> record) {
        reportFailure(record, new RuntimeException("Max retry attempts exceeded"));
    }

    @Override
    public void addToBatch(final RetryableRecord<String, ScanTask> record) {
        final Optional<Report> cachedReport = getCachedReport(record.key());
        if (cachedReport.isPresent()) {
            LOGGER.debug("Processing cached report for {}", record);
            processReport(cachedReport.get(), List.of(record));
            return;
        }

        if (batchStore.get(record.value().getKey()) == null) {
            batchStore.put(record.value().getKey(), record);
        } else {
            LOGGER.warn("Record {} is already in the current batch; Dropping", record);
            return;
        }

        // Note: approximateNumEntries may over-report or under-report when RocksDB is used.
        // It is possible that this condition will be true, even though the store contains
        // more or less entries than config.batchSize.
        // This is an acceptable trade-off here, because it's still a better option than reading
        // entries from the store too often (as it involves de-serializing all of them).
        if (batchStore.approximateNumEntries() >= config.batchSize()) {
            final List<RetryableRecord<String, ScanTask>> batch = currentBatch();
            analyzeBatch(batch);
        }
    }

    @Override
    public void analyzeBatch(final List<RetryableRecord<String, ScanTask>> batch) {
        LOGGER.info("Analyzing batch of {} records", batch.size());
        super.analyzeBatch(batch);

        // Snyk's responses will contain PURLs in lowercase, even if the original PURL we submitted contained
        // uppercase characters. Treat PURLs case-insensitively to avoid any mismatches when correlating results.
        // https://github.com/DependencyTrack/dependencytrack/issues/469
        final Set<String> purls = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);
        final MultivaluedMap<String, RetryableRecord<String, ScanTask>> purlRecords = new MultivaluedTreeMap<>(String.CASE_INSENSITIVE_ORDER);
        for (final RetryableRecord<String, ScanTask> record : batch) {
            purlRecords.add(record.key(), record);
            purls.add(record.key());
        }

        final Page<Issue> page;
        try {
            page = circuitBreaker.executeSupplier(() ->
                    client.getIssues(config.api().orgId().get(), config.api().version().get(), getRecordRequest(purlRecords.keySet())));
            batch.forEach(record -> reportRetryStatus(record, RetryStatus.SUCCEEDED));
        } catch (Throwable e) {
            if (ProcessorUtils.isRetryable(e)) {
                batch.forEach(record -> {
                    LOGGER.warn("Encountered retryable exception while analyzing {}: {}", record, e.getMessage());
                    scheduleForRetry(record);
                });
            } else {
                batch.forEach(record -> {
                    LOGGER.error("Encountered non-retryable exception while analyzing {}", record, e);
                    reportFailure(record, e);
                });
            }
            return;
        }
        if (page == null) {
            return;
        }
        for (final PageData<Issue> pageData : page.data()) {
            if (!isPageDataValid(pageData)) {
                continue;
            }
            String purlInReportedIssue = pageData.attributes().coordinates().get(0).representations().get(1).pkg().url();
            Report mappedReport = getMappedReport(page, purlInReportedIssue);
            final List<RetryableRecord<String, ScanTask>> affectedRecords = purlRecords.get(purlInReportedIssue);
            if (affectedRecords == null) {
                // We either already processed all vulnerabilities for the PURL already,
                // or we're not able to correlate the PURL returned by Snyk.
                if (!purls.contains(purlInReportedIssue)) {
                    // Can't correlate the reported coordinates to any PURL that we
                    // submitted for analysis. It's likely that Snyk returned the coordinates
                    // in a different format than what we submitted. Issue a warning.
                    LOGGER.warn("Reported coordinates do not match any records: {}", pageData.attributes().coordinates());
                }
                continue;
            } else {
                purlRecords.remove(purlInReportedIssue);
            }
            processReport(mappedReport, affectedRecords);
            cacheReport(mappedReport);
        }

        PageMeta pageMeta = page.meta();
        if (pageMeta != null && pageMeta.errors() != null) {
            for (final MetaError metaError : pageMeta.errors()) {
                if (metaError.meta() == null || metaError.meta().purl() == null) {
                    continue;
                }
                var purlWithError = metaError.meta().purl();
                final var errorMessage = "Purl " + purlWithError + " failed with status " + metaError.status() +
                        " due to Snyk error code " + metaError.code() + " : " + metaError.title();
                LOGGER.error(errorMessage);
                //TODO uncomment lines below when batch error response from snyk is fixed
//                for (var purlRecord : purlRecords.get(purlWithError)) {
//                    reportFailure(purlRecord, new RuntimeException(errorMessage));
//                }
//                purlRecords.remove(purlWithError);
            }
        }

        for (final Map.Entry<String, List<RetryableRecord<String, ScanTask>>> unmatchedRecords : purlRecords.entrySet()) {
            // If no vulnerabilities have been identified for a given PURL, there will be no explicit entry for
            // it in Snyk's response. Whenever we have PURLs left that we couldn't correlate with a Snyk result,
            // we have to assume it's not vulnerable.
            // In reality, there is no way for us to differentiate between "no vulnerabilities" and "unable to correlate".

            LOGGER.debug("No results were returned for coordinates {} (affecting {}/{} records in this batch)",
                    unmatchedRecords.getKey(), unmatchedRecords.getValue().size(), batch.size());
            for (final RetryableRecord<String, ScanTask> record : unmatchedRecords.getValue()) {
                final ScannerResult result = ScannerResult.newBuilder()
                        .setScanner(Scanner.SCANNER_SNYK)
                        .setStatus(ScanStatus.SCAN_STATUS_SUCCESSFUL)
                        .build();
                context().forward(record.withKey(record.value().getKey()).withValue(result).withTimestamp(context().currentSystemTimeMs()));
                reportScanResult(NOT_VULNERABLE);
                cacheReport(new Report(unmatchedRecords.getKey(), Bom.newBuilder().build()));
            }
        }
    }

    private Optional<Report> getCachedReport(final String purl) {
        try {
            final Report cachedReport = cache.<String, Report>get(purl.toLowerCase(),
                    key -> {
                        // null values would be cached, so throw an exception instead.
                        // See https://quarkus.io/guides/cache#let-exceptions-bubble-up
                        throw new NoSuchElementException();
                    }).await().indefinitely();
            return Optional.of(cachedReport);
        } catch (Exception e) {
            return Optional.empty();
        }
    }

    private void cacheReport(final Report report) {
        cache.get(report.purl().toLowerCase(), key -> report).await().indefinitely();
    }

    private void processReport(final Report report, List<RetryableRecord<String, ScanTask>> affectedRecords) {
        for (final RetryableRecord<String, ScanTask> record : affectedRecords) {
            final var result = ScannerResult.newBuilder()
                    .setScanner(Scanner.SCANNER_SNYK)
                    .setStatus(ScanStatus.SCAN_STATUS_SUCCESSFUL)
                    .setBom(report.bom())
                    .build();
            context().forward(record.withKey(record.value().getKey()).withValue(result).withTimestamp(context().currentSystemTimeMs()));
            reportScanResult(report.bom().getVulnerabilitiesList().isEmpty() ? NOT_VULNERABLE : VULNERABLE);
        }
    }

    private void reportFailure(final RetryableRecord<String, ScanTask> record, final Throwable failureCause) {
        final var result = ScannerResult.newBuilder()
                .setScanner(Scanner.SCANNER_SNYK)
                .setStatus(ScanStatus.SCAN_STATUS_FAILED)
                .setFailureReason(failureCause.getMessage())
                .build();
        context().forward(record.withKey(record.value().getKey()).withValue(result).withTimestamp(context().currentSystemTimeMs()));
        reportRetryStatus(record, RetryStatus.FAILED);
        reportScanResult("failed");
    }

    private ReportRequest getRecordRequest(Collection<String> purls) {
        var attributes = Map.of("purls", purls);
        var data = new PageData<Map>(null, null, attributes);
        return new ReportRequest(data);
    }

    private Report getMappedReport(Page<Issue> issuePage, String purl) {
        Bom bom = ModelConverterToCdx.convert(CweResolver.getInstance(), severitySourcePriority, issuePage.data(), purl, config.aliasSyncEnabled());
        return new Report(purl, bom);
    }

    private static boolean isPageDataValid(PageData<Issue> pageData) {
        if (pageData != null
                && pageData.attributes() != null
                && pageData.attributes().coordinates() != null
                && pageData.attributes().coordinates().get(0) != null
                && pageData.attributes().coordinates().get(0).representations() != null
                && pageData.attributes().coordinates().get(0).representations().get(1) != null
                && pageData.attributes().coordinates().get(0).representations().get(1).pkg() != null) {
            return true;
        }
        //snyk did not return the correct response so skip this issue from report
        LOGGER.error("Report returned from snyk is not in correct format and does not have all the fields");
        return false;
    }
}
