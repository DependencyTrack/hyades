package org.hyades.processor.snyk;

import com.github.packageurl.PackageURL;
import io.github.resilience4j.circuitbreaker.CircuitBreaker;
import io.github.resilience4j.core.IntervalFunction;
import io.micrometer.core.instrument.MeterRegistry;
import io.quarkus.cache.Cache;
import org.hyades.client.snyk.Issue;
import org.hyades.client.snyk.Page;
import org.hyades.client.snyk.PageData;
import org.hyades.client.snyk.Report;
import org.hyades.client.snyk.ReportRequest;
import org.hyades.client.snyk.SeveritySource;
import org.hyades.client.snyk.SnykClient;
import org.hyades.config.SnykConfig;
import org.hyades.model.AnalyzerIdentity;
import org.hyades.model.ScanTask;
import org.hyades.model.Vulnerability;
import org.hyades.model.VulnerabilityScanKey;
import org.hyades.model.VulnerabilityScanResult;
import org.hyades.model.VulnerabilityScanStatus;
import org.hyades.processor.retry.RetryStatus;
import org.hyades.processor.retry.RetryableRecord;
import org.hyades.processor.retry.RetryingBatchProcessor;
import org.hyades.resolver.CweResolver;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import javax.ws.rs.core.MultivaluedHashMap;
import javax.ws.rs.core.MultivaluedMap;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.NoSuchElementException;
import java.util.Objects;
import java.util.Optional;
import java.util.Set;

import static org.hyades.client.snyk.ModelConverter.convert;
import static org.hyades.util.ProcessorUtils.isRetryable;

public class SnykProcessor extends RetryingBatchProcessor<String, ScanTask, String, VulnerabilityScanResult, VulnerabilityScanKey> {

    private static final Logger LOGGER = LoggerFactory.getLogger(SnykProcessor.class);

    private final SnykClient client;
    private final SnykConfig config;
    private final Cache cache;
    private final CircuitBreaker circuitBreaker;
    private final SeveritySource severitySource;
    private final String batchStoreName;

    private static final String VULNERABLE = "vulnerable";
    private static final String NOT_VULNERABLE = "not_vulnerable";

    private static final Set<String> SUPPORTED_PURL_TYPES = Set.of(
            PackageURL.StandardTypes.CARGO,
            "cocoapods", // Not defined in StandardTypes
            PackageURL.StandardTypes.COMPOSER,
            PackageURL.StandardTypes.GEM,
            PackageURL.StandardTypes.GENERIC,
            PackageURL.StandardTypes.HEX,
            PackageURL.StandardTypes.MAVEN,
            PackageURL.StandardTypes.NPM,
            PackageURL.StandardTypes.NUGET,
            PackageURL.StandardTypes.PYPI
    );

    SnykProcessor(final SnykClient snykClient, final SnykConfig config, final Cache cache, final CircuitBreaker circuitBreaker,
                  final SeveritySource severitySource, final String batchStoreName,
                  final String retryStoreName, final IntervalFunction retryIntervalFunction,
                  final int retryMaxAttempts, final MeterRegistry meterRegistry) {
        super(retryStoreName, retryIntervalFunction, retryMaxAttempts, meterRegistry, batchStoreName, config.batchInterval());
        this.client = snykClient;
        this.config = config;
        this.cache = cache;
        this.circuitBreaker = circuitBreaker;
        this.severitySource = severitySource;
        this.batchStoreName = batchStoreName;
    }

    @Override
    public void process(final RetryableRecord<String, ScanTask> record) {
        addToBatch(record);
    }

    @Override
    protected VulnerabilityScanKey retryKey(final String key, final ScanTask value) {
        return value.vulnerabilityScanKey();
    }

    @Override
    protected void onRetry(final RetryableRecord<String, ScanTask> record) {
        addToBatch(record);
    }

    @Override
    protected void onMaxRetriesExceeded(final RetryableRecord<String, ScanTask> record) {
        reportFailure(record, new RuntimeException("Max retry attempts exceeded"));
    }

    @Override
    public void addToBatch(final RetryableRecord<String, ScanTask> record) {
        if (record.value() != null
                && record.value().component() != null
                && record.value().component().getPurl() != null
                && !SUPPORTED_PURL_TYPES.contains(record.value().component().getPurl().getType())) {
            LOGGER.debug("PURL of type {} is not supported", record.value().component().getPurl().getType());
            final var result = VulnerabilityScanResult.builder(record.value().vulnerabilityScanKey(), AnalyzerIdentity.SNYK_ANALYZER)
                    .withStatus(VulnerabilityScanStatus.SUCCESSFUL)
                    .withVulnerabilities(Collections.emptyList())
                    .build();
            context().forward(record.withValue(result).withTimestamp(context().currentSystemTimeMs()));
            reportScanResult(NOT_VULNERABLE);
            return;
        }

        final Optional<Report> cachedReport = getCachedReport(record.key());
        if (cachedReport.isPresent()) {
            LOGGER.debug("Processing cached report for {}", record);
            processReport(cachedReport.get(), List.of(record));
            return;
        }

        if (batchStore.get(record.value().vulnerabilityScanKey()) == null) {
            batchStore.put(record.value().vulnerabilityScanKey(), record);
        } else {
            LOGGER.warn("Record {} is already in the current batch; Dropping", record);
            return;
        }

        if (batchStore.approximateNumEntries() >= config.batchSize()) {
            final List<RetryableRecord<String, ScanTask>> batch = currentBatch();
            batch.forEach(batchRecord -> batchStore.delete(batchRecord.value().vulnerabilityScanKey()));
            analyzeBatch(batch);
        }
    }

    @Override
    public void analyzeBatch(final List<RetryableRecord<String, ScanTask>> batch) {
        LOGGER.info("Analyzing batch of {} records", batch.size());
        super.analyzeBatch(batch);

        final MultivaluedMap<String, RetryableRecord<String, ScanTask>> purlRecords = new MultivaluedHashMap<>();
        for (final RetryableRecord<String, ScanTask> record : batch) {
            purlRecords.add(record.key(), record);
        }

        final Page<Issue> page;
        try {
            page = circuitBreaker.executeSupplier(() ->
                    client.getIssues(config.api().orgId().get(), config.api().version().get(), getRecordRequest(purlRecords.keySet())));
            batch.forEach(record -> reportRetryStatus(record, RetryStatus.SUCCEEDED));
        } catch (Throwable e) {
            if (isRetryable(e)) {
                batch.forEach(record -> {
                    LOGGER.warn("Encountered retryable exception while analyzing {}: {}", record, e.getMessage());
                    scheduleForRetry(record);
                });
            } else {
                batch.forEach(record -> {
                    LOGGER.error("Encountered non-retryable exception while analyzing {}", record, e);
                    reportFailure(record, e);
                });
            }
            return;
        }
        if (page == null) {
            return;
        }
        for (final PageData<Issue> pageData : page.data()) {
            if (!isPageDataValid(pageData)) {
                continue;
            }
            String purlInReportedIssue = pageData.attributes().coordinates().get(0).representations().get(1).pkg().url();
            Report mappedReport = getMappedReport(page, purlInReportedIssue);
            final List<RetryableRecord<String, ScanTask>> affectedRecords = purlRecords.get(purlInReportedIssue);
            if (affectedRecords == null) {
                LOGGER.warn("Reported coordinates do not match any records: " + pageData.attributes().coordinates());
                continue;
            } else {
                purlRecords.remove(purlInReportedIssue);
            }
            processReport(mappedReport, affectedRecords);
            cacheReport(mappedReport);
        }

        for (final Map.Entry<String, List<RetryableRecord<String, ScanTask>>> unmatchedRecords : purlRecords.entrySet()) {
            LOGGER.warn("No results were returned for coordinates {} (affecting {}/{} records in this batch)",
                    unmatchedRecords.getKey(), unmatchedRecords.getValue().size(), batch.size());
            // TODO: Should we cache "no vulnerabilities" for this case, too?
            for (final RetryableRecord<String, ScanTask> record : unmatchedRecords.getValue()) {
                final VulnerabilityScanResult result = VulnerabilityScanResult.builder(record.value().vulnerabilityScanKey(), AnalyzerIdentity.SNYK_ANALYZER)
                        .withStatus(VulnerabilityScanStatus.SUCCESSFUL)
                        .withVulnerabilities(Collections.emptyList())
                        .build();
                context().forward(record.withValue(result).withTimestamp(context().currentSystemTimeMs()));
                reportScanResult(NOT_VULNERABLE);
            }
        }
    }

    private Optional<Report> getCachedReport(final String purl) {
        try {
            final Report cachedReport = cache.<String, Report>get(purl,
                    key -> {
                        // null values would be cached, so throw an exception instead.
                        // See https://quarkus.io/guides/cache#let-exceptions-bubble-up
                        throw new NoSuchElementException();
                    }).await().indefinitely();
            return Optional.of(cachedReport);
        } catch (Exception e) {
            return Optional.empty();
        }
    }

    private void cacheReport(final Report report) {
        cache.get(report.purl(), key -> report).await().indefinitely();
    }

    private void processReport(final Report report, List<RetryableRecord<String, ScanTask>> affectedRecords) {

        for (final RetryableRecord<String, ScanTask> record : affectedRecords) {
            final var result = VulnerabilityScanResult.builder(record.value().vulnerabilityScanKey(), AnalyzerIdentity.SNYK_ANALYZER)
                    .withStatus(VulnerabilityScanStatus.SUCCESSFUL)
                    .withVulnerabilities(report.vulnerabilities())
                    .build();
            context().forward(record.withValue(result).withTimestamp(context().currentSystemTimeMs()));
            reportScanResult(report.vulnerabilities().isEmpty() ? NOT_VULNERABLE : VULNERABLE);
        }
    }

    private void reportFailure(final RetryableRecord<String, ScanTask> record, final Throwable failureCause) {
        final var result = VulnerabilityScanResult.builder(record.value().vulnerabilityScanKey(), AnalyzerIdentity.SNYK_ANALYZER)
                .withStatus(VulnerabilityScanStatus.FAILED)
                .withFailureReason(failureCause.getMessage())
                .build();
        context().forward(record.withValue(result).withTimestamp(context().currentSystemTimeMs()));
        reportRetryStatus(record, RetryStatus.FAILED);
        reportScanResult("failed");
    }

    private ReportRequest getRecordRequest(Collection<String> purls) {
        var attributes = Map.of("purls", purls);
        PageData<HashMap> data = new PageData(null, null, attributes);
        return new ReportRequest(data);
    }

    private Report getMappedReport(Page<Issue> issuePage, String coordinate) {
        List<Vulnerability> vulnerabilities = Optional.ofNullable(issuePage)
                .map(Page::data)
                .orElseGet(Collections::emptyList)
                .stream()
                .filter(data -> Objects.equals(data.type(), "issue")
                        && coordinate.equals(data.attributes().coordinates().get(0).representations().get(1).pkg().url()))
                .map(data -> convert(CweResolver.getInstance(), severitySource, data))
                .toList();

        return new Report(coordinate, vulnerabilities);
    }

    private static boolean isPageDataValid(PageData<Issue> pageData) {
        if (pageData != null
                && pageData.attributes() != null
                && pageData.attributes().coordinates() != null
                && pageData.attributes().coordinates().get(0) != null
                && pageData.attributes().coordinates().get(0).representations() != null
                && pageData.attributes().coordinates().get(0).representations().size() == 2
                && pageData.attributes().coordinates().get(0).representations().get(1) != null
                && pageData.attributes().coordinates().get(0).representations().get(1).pkg() != null) {
            //snyk did not return the correct response so skip this issue from report
            LOGGER.error("Report returned from snyk is not in correct format and does not have all the fields");
            return true;
        }
        return false;
    }
}
