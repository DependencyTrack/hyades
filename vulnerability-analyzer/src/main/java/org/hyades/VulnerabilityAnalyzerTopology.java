package org.hyades;

import com.github.packageurl.MalformedPackageURLException;
import com.github.packageurl.PackageURL;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.common.utils.Bytes;
import org.apache.kafka.streams.KeyValue;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.Topology;
import org.apache.kafka.streams.kstream.Branched;
import org.apache.kafka.streams.kstream.BranchedKStream;
import org.apache.kafka.streams.kstream.Consumed;
import org.apache.kafka.streams.kstream.Grouped;
import org.apache.kafka.streams.kstream.Joined;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.KTable;
import org.apache.kafka.streams.kstream.Materialized;
import org.apache.kafka.streams.kstream.Named;
import org.apache.kafka.streams.kstream.Predicate;
import org.apache.kafka.streams.kstream.Produced;
import org.apache.kafka.streams.kstream.Repartitioned;
import org.apache.kafka.streams.state.KeyValueStore;
import org.hyades.common.KafkaTopic;
import org.hyades.processor.misc.TombstoneEmittingProcessorSupplier;
import org.hyades.processor.scanner.ScanProcessorSupplier;
import org.hyades.proto.KafkaProtobufSerde;
import org.hyades.proto.vulnanalysis.internal.v1beta1.ExpectedScans;
import org.hyades.proto.vulnanalysis.internal.v1beta1.ScanTask;
import org.hyades.proto.vulnanalysis.internal.v1beta1.Scans;
import org.hyades.proto.vulnanalysis.v1.Component;
import org.hyades.proto.vulnanalysis.v1.ScanCommand;
import org.hyades.proto.vulnanalysis.v1.ScanKey;
import org.hyades.proto.vulnanalysis.v1.ScanResult;
import org.hyades.proto.vulnanalysis.v1.ScanStatus;
import org.hyades.proto.vulnanalysis.v1.Scanner;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import javax.enterprise.context.ApplicationScoped;
import javax.enterprise.inject.Instance;
import javax.enterprise.inject.Produces;
import javax.inject.Inject;
import java.time.Duration;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

import static org.hyades.commonutil.KafkaStreamsUtil.processorNameConsume;
import static org.hyades.commonutil.KafkaStreamsUtil.processorNameProduce;
import static org.hyades.proto.vulnanalysis.v1.Scanner.SCANNER_NONE;

@ApplicationScoped
public class VulnerabilityAnalyzerTopology {

    private static final Logger LOGGER = LoggerFactory.getLogger(VulnerabilityAnalyzerTopology.class);

    private final Instance<ScanProcessorSupplier> scanProcessorSuppliers;

    @Inject
    public VulnerabilityAnalyzerTopology(final Instance<ScanProcessorSupplier> scanProcessorSuppliers) {
        this.scanProcessorSuppliers = scanProcessorSuppliers;
    }

    @Produces
    public Topology topology() {
        final var streamsBuilder = new StreamsBuilder();

        final var expectedScansSerde = new KafkaProtobufSerde<>(ExpectedScans.parser());
        final var scansSerde = new KafkaProtobufSerde<>(Scans.parser());
        final var scanCommandSerde = new KafkaProtobufSerde<>(ScanCommand.parser());
        final var scanKeySerde = new KafkaProtobufSerde<>(ScanKey.parser());
        final var scanResultSerde = new KafkaProtobufSerde<>(ScanResult.parser());
        final var scanTaskSerde = new KafkaProtobufSerde<>(ScanTask.parser());

        final KStream<ScanKey, ScanCommand> scanCommandStream = streamsBuilder
                .stream(KafkaTopic.VULN_ANALYSIS_COMPONENT.getName(), Consumed
                        .with(scanKeySerde, scanCommandSerde)
                        .withName(processorNameConsume(KafkaTopic.VULN_ANALYSIS_COMPONENT)));

        final KStream<ScanKey, ScanResult> resultStream = streamsBuilder
                .stream(KafkaTopic.VULN_ANALYSIS_RESULT.getName(), Consumed
                        .with(scanKeySerde, scanResultSerde)
                        .withName(processorNameConsume(KafkaTopic.VULN_ANALYSIS_RESULT)));

        // For every incoming command, determine which scanners are enabled, and capable
        // of scanning its component. Generate a scan task for each capable scanner.
        final KStream<ScanKey, ScanTask> scanTaskStream = scanCommandStream
                .flatMapValues(this::generateScanTasks, Named.as("generate_scan_tasks"));

        // Events are re-keyed from scan key to component identifier (CPE, PURL, etc.).
        // Keying by identifier will ensure that the same identifier will always
        // be scanned by the same stream task, allowing for efficient and reliable cache lookups.
        //
        // The priority of identifiers to use as key is as follows:
        //   1. PURL
        //   2. CPE
        //   3. (Others, TBD)
        //
        // The assumption is that PURL will cover most cases, and having one or the other outlier
        // where PURL and CPE refer to different components is acceptable in practice.
        final BranchedKStream<String, ScanTask> branchedScanTaskStream = scanTaskStream
                .selectKey(this::selectComponentIdentifier, Named.as("re-key_to_component_identifier"))
                .split(Named.as("applicable_scanner-"));

        // Route the generated scan tasks to the topics of the respective scanners.
        //
        // Each scanner has its own topic. Because partitions are the means of enabling
        // parallelism in Kafka, and scanners work at different paces, utilizing the same
        // input topic for all scanners is not practical. Scanner topics are managed by
        // Kafka Streams and will be automatically created if they don't exist yet.
        for (final ScanProcessorSupplier scanProcessorSupplier : scanProcessorSuppliers) {
            final Scanner scannerIdentity = scanProcessorSupplier.scannerIdentity();
            final String scannerShortName = shortName(scannerIdentity);

            if (!scanProcessorSupplier.isEnabled()) {
                LOGGER.info("""
                        Not registering stream processor for scanner {}, \
                        because it is disabled""", scannerShortName);
                continue;
            }

            LOGGER.info("Registering stream processor for scanner {}", scannerShortName);
            branchedScanTaskStream.branch(shouldScanWith(scanProcessorSupplier.scannerIdentity()), Branched
                    .<String, ScanTask>withConsumer(stream -> stream
                            .repartition(Repartitioned
                                    .with(Serdes.String(), scanTaskSerde)
                                    .withName("scan-task-%s".formatted(scannerShortName))
                                    .withNumberOfPartitions(scanProcessorSupplier.topicPartitions()))
                            .process(scanProcessorSupplier,
                                    Named.as("scan_with_%s".formatted(scannerShortName)))
                            .selectKey((identifier, scanResult) -> scanResult.getKey(),
                                    Named.as("re-key_%s_result_to_scan_key".formatted(scannerShortName)))
                            .to(KafkaTopic.VULN_ANALYSIS_RESULT.getName(), Produced
                                    .with(scanKeySerde, scanResultSerde)
                                    .withName(processorNameProduce(KafkaTopic.VULN_ANALYSIS_RESULT, "%s_result".formatted(scannerShortName)))))
                    .withName(scannerShortName));
        }

        // For scan tasks that can not be handled by any scanner,
        // immediately emit a completion event.
        branchedScanTaskStream.defaultBranch(Branched
                .<String, ScanTask>withConsumer(stream -> stream
                        .map((identifier, task) -> KeyValue.pair(task.getKey(),
                                        ScanResult.newBuilder()
                                                .setKey(task.getKey())
                                                .setScanner(SCANNER_NONE)
                                                .setStatus(ScanStatus.SCAN_STATUS_COMPLETE)
                                                .build()),
                                Named.as("map_unmatched_scan_task_to_completion_event"))
                        .to(KafkaTopic.VULN_ANALYSIS_RESULT.getName(), Produced
                                .with(scanKeySerde, scanResultSerde)
                                .withName(processorNameProduce(KafkaTopic.VULN_ANALYSIS_RESULT,
                                        "completion_event_for_unscannable_component"))))
                .withName(shortName(SCANNER_NONE)));

        // Based on the generated scan tasks, determine for which scanners we're expecting results.
        // For each scan key, materialize a collection of scanner identities in a table.
        final KTable<ScanKey, ExpectedScans> expectedScanResultsTable = scanTaskStream
                // Emit tombstone events for scan keys for which no events have been received
                // for >= 1h (stream time). Check every 5min (also stream time) for eligible keys.
                // This keeps the KTable from growing indefinitely.
                .processValues(new TombstoneEmittingProcessorSupplier<>(
                        "expected-scan-results-last-update-store",
                        scanKeySerde, Duration.ofMinutes(5), Duration.ofHours(1),
                        scanKey -> ScanTask.newBuilder()
                                .setKey(scanKey)
                                .setScanner(SCANNER_NONE)
                                .setTombstone(true)
                                .build()
                ), Named.as("emit_expected_scan_results_table_tombstones"))
                .groupByKey(Grouped
                        .with(scanKeySerde, scanTaskSerde)
                        .withName("scan-task-by-scan-key"))
                .aggregate(() -> ExpectedScans.newBuilder().build(),
                        this::aggregateExpectedScanResults,
                        Named.as("aggregate_expected_scan_results"),
                        Materialized
                                .<ScanKey, ExpectedScans, KeyValueStore<Bytes, byte[]>>as("expected-scan-results-table")
                                .withKeySerde(scanKeySerde)
                                .withValueSerde(expectedScansSerde)
                                .withStoreType(Materialized.StoreType.IN_MEMORY));

        // Join the results we receive from scanners with the table of expected scan results.
        final KStream<ScanKey, Scans> completedScansStream = resultStream
                // Filter out completion events, otherwise we'll be running into an infinite loop.
                .filter((scanKey, result) -> ScanStatus.SCAN_STATUS_COMPLETE != result.getStatus(),
                        Named.as("filter_out_completion_events"))
                .join(expectedScanResultsTable, (result, expected) -> {
                    final var statuses = new HashMap<String, ScanStatus>();
                    expected.getScannersList().forEach(scanner -> statuses.put(scanner.name(), ScanStatus.SCAN_STATUS_PENDING));
                    statuses.put(result.getScanner().name(), result.getStatus());
                    return Scans.newBuilder().putAllStatuses(statuses).build();
                }, Joined
                        .with(scanKeySerde, scanResultSerde, expectedScansSerde)
                        .withName("join_results_with_expected_scan_results"));

        // Aggregate completed scans per scan key and materialize this data in a table.
        // Table values will include the reported status by each scanner, e.g.
        //   INTERNAL -> SUCCESSFUL
        //   OSSINDEX -> FAILED
        //   SNYK     -> PENDING
        final KTable<ScanKey, Scans> completedScansTable = completedScansStream
                // Emit tombstone events for ScanKeys for which no events have been received
                // for >= 1h (stream time). Check every 5min (also stream time) for eligible keys.
                // This keeps the KTable from growing indefinitely.
                .processValues(new TombstoneEmittingProcessorSupplier<>(
                        "completed-scans-table-last-update-store",
                        scanKeySerde, Duration.ofMinutes(5), Duration.ofHours(1),
                        scanKey -> Scans.newBuilder().setTombstone(true).build()
                ), Named.as("emit_completed_scans_table_tombstones"))
                .groupByKey(Grouped
                        .with(scanKeySerde, scansSerde)
                        .withName("completed-scans-by-scan-key"))
                .aggregate(
                        Scans.newBuilder()::build,
                        this::aggregateCompletedScans,
                        Named.as("aggregate_completed_scans"),
                        Materialized
                                .<ScanKey, Scans, KeyValueStore<Bytes, byte[]>>as("completed-scans-table")
                                .withKeySerde(scanKeySerde)
                                .withValueSerde(scansSerde)
                                .withStoreType(Materialized.StoreType.IN_MEMORY)
                                .withCachingDisabled()); // Ensure all changes will be forwarded

        // Once all expected scans for a given scan key are completed (not PENDING),
        // emit a completion event for that scan key to the result stream.
        //
        // This allows downstream systems to determine when no further scan results
        // are to be expected.
        completedScansTable
                .toStream(Named.as("stream_completed_scans"))
                // We receive an event for every change of the aggregate here,
                // so suppress events that do not represent a completed scan.
                .filter((scanKey, completedScans) -> completedScans != null
                                && completedScans.getStatusesMap().values().stream().noneMatch(ScanStatus.SCAN_STATUS_PENDING::equals),
                        Named.as("filter_completed_scans"))
                .mapValues((scanKey, completedScans) -> ScanResult.newBuilder()
                                .setKey(scanKey)
                                .setScanner(SCANNER_NONE)
                                .setStatus(ScanStatus.SCAN_STATUS_COMPLETE)
                                .build(),
                        Named.as("map_completed_scans_to_completion_event"))
                .to(KafkaTopic.VULN_ANALYSIS_RESULT.getName(), Produced
                        .with(scanKeySerde, scanResultSerde)
                        .withName(processorNameProduce(KafkaTopic.VULN_ANALYSIS_RESULT, "completion_event")));

        return streamsBuilder.build();
    }

    private List<ScanTask> generateScanTasks(final ScanKey scanKey, final ScanCommand scanCommand) {
        final var tasks = new ArrayList<ScanTask>();
        if (!scanCommand.hasComponent()) {
            return tasks;
        }

        scanProcessorSuppliers.stream()
                .filter(ScanProcessorSupplier::isEnabled)
                .filter(supplier -> supplier.canProcess(scanCommand.getComponent()))
                .map(supplier -> ScanTask.newBuilder()
                        .setKey(scanKey)
                        .setScanner(supplier.scannerIdentity())
                        .setComponent(scanCommand.getComponent())
                        .build())
                .forEach(tasks::add);

        if (tasks.isEmpty()) {
            tasks.add(ScanTask.newBuilder()
                    .setKey(scanKey)
                    .setScanner(SCANNER_NONE)
                    .build());
        }

        return tasks;
    }

    private String selectComponentIdentifier(final ScanKey scanKey, final ScanTask scanTask) {
        if (!scanTask.hasComponent()) {
            return scanKey.getComponentUuid();
        }

        final Component component = scanTask.getComponent();
        if (component.hasPurl()) {
            try {
                return new PackageURL(component.getPurl()).getCoordinates();
            } catch (MalformedPackageURLException e) {
                LOGGER.warn("Unable to select PURL as component identifier for {}; Falling back to {}",
                        scanKey, scanKey.getComponentUuid(), e);
            }
        } else if (component.hasCpe()) {
            return component.getCpe();
        }

        return scanKey.getComponentUuid();
    }

    private <K> Predicate<K, ScanTask> shouldScanWith(final Scanner scanner) {
        return (key, scanTask) -> scanTask.getScanner() == scanner;
    }

    private String shortName(final Scanner scanner) {
        return scanner.name().replaceAll("^SCANNER_", "").toLowerCase();
    }

    private <K> ExpectedScans aggregateExpectedScanResults(final K key, final ScanTask scanTask, final ExpectedScans aggregate) {
        if (scanTask.hasTombstone() && scanTask.getTombstone()) {
            return null;
        }

        return ExpectedScans.newBuilder(aggregate)
                .addScanners(scanTask.getScanner())
                .build();
    }

    private <K> Scans aggregateCompletedScans(final K key, final Scans scans, final Scans aggregate) {
        if (scans.hasTombstone() && scans.getTombstone()) {
            return null;
        }

        final Map<String, ScanStatus> statuses;
        if (!aggregate.getStatusesMap().isEmpty()) {
            statuses = new HashMap<>(aggregate.getStatusesMap());
            scans.getStatusesMap().entrySet().stream()
                    .filter(entry -> ScanStatus.SCAN_STATUS_PENDING != entry.getValue())
                    .forEach(entry -> statuses.put(entry.getKey(), entry.getValue()));
        } else {
            statuses = scans.getStatusesMap();
        }

        return Scans.newBuilder()
                .putAllStatuses(statuses)
                .build();
    }

}
