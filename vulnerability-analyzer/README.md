# Vulnerability Analyzer

The vulnerability analyzer is responsible for scanning components for known vulnerabilities.

A scan can be triggered by emitting a *scan command* event to the `dtrack.vuln-analysis.component` topic.  
The event key must adhere to the format `<SCAN_TOKEN>/<COMPONENT_UUID>`, where:

* `SCAN_TOKEN` is an arbitrary string used to correlate one or more scans with each other
* `COMPONENT_UUID` is the UUID of the to-be-scanned component in the API server's database

In practice, valid event key may end up looking like this:

```
6cb18e5f-518b-44bc-a042-ba3794ba0e6e/848f1dba-08bb-40dc-8bf8-354d9fe8019c
```

The event value must contain all necessary information for identifying the component that shall be scanned, in JSON format.
At the very least, it should include:

* The component's UUID
* The component's CPE and / or PURL

A minimal event value would be:

```json
{
  "uuid": "848f1dba-08bb-40dc-8bf8-354d9fe8019c",
  "purl": "pkg:maven/foo/bar@1.2.3"
}
```

Internally, a *scan task* will be generated for each scanner that is both:

1. Enabled (see [`CONFIGURATION.md`])
2. Capable of scanning the component

> **Note**  
> Whether a scanner is capable scanning a given component primarily depends on the component's identifiers.   
> While most scanners are capable of dealing with PURLs, only the internal analyzer is capable of handling CPEs.

*Scan tasks* are re-keyed to the "primary" identifier of the component. If a PURL is available, the coordinates
(type, namespace, name, and version, but excluding qualifiers and subpaths) of it will be used. Alternatively, 
CPE or UUID will be used. This re-key operation is performed to ensure that tasks for the same component identity
are published to the same topic partition.

Each scan task is then forwarded to the topic of the respective scanner. As the number of partitions is the means of
achieving parallelism in Kafka consumers, it is expected that the partition count will differ from scanner to scanner.

OSS Index allows for batching of up to 128 PURLs per request, while Snyk requires individual PURLs to be submitted.
In (local) testing, requests to OSS Index take about 600-900ms to complete, whereas requests to Snyk take about 200-400ms.
In order to achieve a throughput with Snyk that is similar to what is possible with OSS Index, the Snyk topic requires
a lot more partitions. The number of partitions are configurable for each scanner, see [`CONFIGURATION.md`].

Scanner results are re-keyed back to the *scan key* (`<SCAN_TOKEN>/<COMPONENT_UUID>`) again, and finally published to
the `dtrack.vuln-analysis.result` topic. A *scan result* is a JSON object composed of the following fields:

* `scanKey`: The *scan key*, as also used as event key
  * Keeping it in the event value is required for internal processing
* `scanner`: The scanner that produced this result
* `status`: Status of the scan
  * Can be either `SUCCESSFUL` or `FAILED`
* `vulnerabilities`: Any vulnerabilities that have been identified
  * When `status` is `SUCCESSFUL`
* `failureReason`: Reason for the failure
  * When `status` is `FAILED`

Applications consuming from `dtrack.vuln-analysis.result` can correlate results with their initial *scan command*
based on the *scan key*.

In order to provide a way to determine when all capable scanners completed for a given *scan key*, the vulnerability
analyzer application consumes from `dtrack.vuln-analysis.result`, too. By observing the *scan tasks* created and the
*scan results* received, it is able to deduce when the initial *scan command* has been completed.

Once completion is detected, an additional *completion event* is published to `dtrack.vuln-analysis.result`,
with the `scanner` field set to `NONE`, and `status` set to `COMPLETE`. 

For a component that was scanned by both the internal scanner and OSS Index, a complete series of events
in the `dtrack.vuln-analysis.result` topic would look like this:

![Scan results](../docs/vuln-analyzer_scan-results.png)

## Streams Topology

The vulnerability analyzer is implemented as [Kafka Streams] application. As such, it is possible to generate a diagram
of the [topology] that every single event processed by application will be funnelled through.

![Kafka Streams Topology](../docs/vuln-analyzer_topology.png)

[`CONFIGURATION.md`]: ../CONFIGURATION.md
[Kafka Streams]: https://kafka.apache.org/33/documentation/streams/core-concepts
[topology]: https://kafka.apache.org/33/documentation/streams/core-concepts#streams_topology